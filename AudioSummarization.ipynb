{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conda environment with the required packages (Python 3.9).\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83697f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "FRAME_RATE = 16000\n",
    "CHANNELS = 1\n",
    "\n",
    "model = Model(model_name='vosk-model-en-us-0.22')\n",
    "\n",
    "recognizer = KaldiRecognizer(model, FRAME_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3756bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def split_audio(file_path, output_dir, num_splits):\n",
    "    # Load the audio file.\n",
    "    audio = AudioSegment.from_mp3(file_path)\n",
    "\n",
    "    # Calculate the duration of each split.\n",
    "    split_duration = len(audio) // num_splits\n",
    "\n",
    "    # Ensure the output directory exists.\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Split and export the audio.\n",
    "    for i in range(num_splits):\n",
    "        start_time = i * split_duration\n",
    "        end_time = (i + 1) * split_duration if i < num_splits - 1 else len(audio)\n",
    "        split_audio = audio[start_time:end_time]\n",
    "        split_audio.export(f\"{output_dir}/split_{i + 1}.mp3\", format=\"mp3\")\n",
    "        print(f\"Exported: split_{i + 1}.mp3\")\n",
    "\n",
    "file_path = \"/home/benyamain/Desktop/AudioSummarization/Karpathy_GPT2.mp3\"\n",
    "output_dir = \"/home/benyamain/Desktop/AudioSummarization/\"\n",
    "num_splits = 16\n",
    "\n",
    "split_audio(file_path, output_dir, num_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af364472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "mp3 = AudioSegment.from_mp3('/home/benyamain/Desktop/AudioSummarization/split_1.mp3')\n",
    "mp3 = mp3.set_channels(CHANNELS)\n",
    "mp3 = mp3.set_frame_rate(FRAME_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this cell if your audio file is too large!\n",
    "mp3.raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4956e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.AcceptWaveform(mp3.raw_data)\n",
    "result = recognizer.Result()\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "text = json.loads(result)['text']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c163cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "# Requires this model, 'vosk-recasepunc-en-0.22', which can be found through this link: https://alphacephei.com/vosk/models\n",
    "cased = subprocess.check_output(\"python3 recasepunc/recasepunc.py predict recasepunc/checkpoint\", shell=True, text=True, input=text)\n",
    "cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e7a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_recognition(filename):\n",
    "    model = Model(model_name=\"vosk-model-en-us-0.22\")\n",
    "    \n",
    "    recognizer = KaldiRecognizer(model, FRAME_RATE)\n",
    "    recognizer.SetWords(True)\n",
    "    \n",
    "    mp3 = AudioSegment.from_mp3(filename)\n",
    "    mp3 = mp3.set_channels(CHANNELS)\n",
    "    mp3 = mp3.set_frame_rate(FRAME_RATE)\n",
    "    \n",
    "    step = 45000\n",
    "    transcript = \"\"\n",
    "    \n",
    "    for i in range(0, len(mp3), step):\n",
    "        print(f\"Progress: {i/len(mp3)}\")\n",
    "        segment = mp3[i:i+step]\n",
    "        \n",
    "        recognizer.AcceptWaveform(segment.raw_data)\n",
    "        result = recognizer.Result()\n",
    "        \n",
    "        text = json.loads(result)[\"text\"]\n",
    "        transcript += text\n",
    "    \n",
    "    cased = subprocess.check_output('python3 recasepunc/recasepunc.py predict recasepunc/checkpoint', shell=True, text=True, input=transcript)\n",
    "    \n",
    "    return cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_recognition('/home/benyamain/Desktop/AudioSummarization/split_1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54821dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcript.txt\") as f:\n",
    "    transcript = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe63a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match token length of model (1024)\n",
    "split_tokens = transcript.split(\" \")\n",
    "docs = []\n",
    "\n",
    "for i in range(0, len(split_tokens), 850):\n",
    "    selection = \" \".join(split_tokens[i:(i+850)])\n",
    "    docs.append(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727913b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs\n",
    "summaries = summarizer(docs)\n",
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = \"\\n\\n\".join(d['summary_text'] for d in summaries)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
